---
title: "p8105_hw2_sl5685"
author: "Shumei Liu"
date: "2024-10-02"
output: github_document
---

```{r}
library(tidyverse)
library(readxl)
```

### Problem 1

```{r}
trans_ent = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |> 
  janitor::clean_names() |> 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, vending, entrance_type, ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

trans_ent
```

This dataset contains 19 variables and 1,868 rows. The variables are line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route 7, route8, route9, route10, route11, entry, vending, entrance_type and ada. 

For the data cleaning, first read csv file and clean the names of each columns. Then, select all the variables that we need and use `mutate` convert data from character to a logical variable. The resulting dataset is 1,868 x 19. These data are not tidy.

###### Distinct station

```{r}
trans_ent |> 
  select(station_name, line) |> 
  distinct()
```

There are 465 distinct stations.

###### ADA compliant

```{r}
trans_ent |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

84 stations are ADA compliant.

###### Proportion without vending

```{r}
trans_ent |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```

###### Serve the A train

```{r}
trans_ent |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
```

###### Serve the A train and ADA compliant

```{r}
trans_ent |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

### Problem 2

Mr. Trash Wheel

```{r}
mr_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
                      sheet = "Mr. Trash Wheel") %>%
  janitor::clean_names() |>
  select(-c(x15, x16)) |>
  drop_na() |>
  mutate(sports_balls = as.integer(round(sports_balls))) |>
  mutate(name = "Mr. Trash Wheel") |>
  relocate(name)

mr_df
```

Professor Trash Wheel

```{r}
prof_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
                      sheet = "Professor Trash Wheel") %>%
  janitor::clean_names() |>
  drop_na() |>
  mutate(year = as.character(year)) |>
  mutate(name = "Professor Trash Wheel") |>
  relocate(name)

prof_df
```

Gwynnda Trash Wheel

```{r}
ga_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
                      sheet = "Gwynnda Trash Wheel") %>%
  janitor::clean_names() |>
  mutate(year = as.character(year)) |>
  mutate(name = "Gwynnda Trash Wheel") |>
  relocate(name)

ga_df
```

Binding rows

```{r}
wheel_tidy = bind_rows(mr_df, prof_df, ga_df)
  
wheel_tidy
```

```{r, include = FALSE}
#Total number of cigarette butts collected by Gwynnda in June of 2022
cig_butts = ga_df %>%
  filter(format(date, "%Y-%m") == "2022-06")
```

After cleaning, the dataset includes a total of `r nrow(wheel_tidy)` observations, with each observation representing a specific dumpster filled by one of the trash wheels. The example of key variables include `date`, `month`, `year`, `weight_tons`, and `cigarette_butts`. For available data, the total weight of trash collected by Professor Trash Wheel was `r sum(prof_df$weight_tons)` tons. The total number of cigarette butts collected by Gwynnda in June of 2022 was `r sum(cig_butts$cigarette_butts)`.

### Problem 3

First part

```{r}
bakers = read_csv("data/bakers.csv") %>%
  janitor::clean_names() |>
  rename(baker = baker_name)
```

```{r}
bakes = read_csv("data/bakes.csv") %>%
  janitor::clean_names()
```

```{r}
results = read_csv("data/results.csv", skip = 2) 

colnames(results) <- c("series", "episode", "baker", "technical", "result")

results_cleaned = results %>%
  filter(!is.na(series) & !is.na(episode) & !is.na(baker))
```

```{r}
bakers_bakes = 
  left_join(bakes, bakers, by = c("baker", "series"))
```

```{r}
final_dataset = 
  left_join(bakers_bakes, results_cleaned, by = c("series", "episode", "baker"))
```

```{r}
final_dataset <- final_dataset %>%
  select(series, episode, baker, baker_age, baker_occupation, hometown, signature_bake, show_stopper, technical, result)
```

```{r}
write_csv(final_dataset, "data/final_bake_dataset.csv")
```

First, I imported the data using `read_csv` and renamed each column to something easier to work with. I renamed `baker_name` to `baker`, removed the first two rows for the results dataset, and removed rows with all `NA` values in the results dataset. I merged bakers and bakes datasets based on `baker` and `series`, and then merged the combined dataset with the results dataset on `series`, `episode`, and `baker`. Finally, I reordered the columns and exported the CSV file. The final dataset has 548 rows and 10 variables, and it includes information about each baker, their bakes, technical scores, and results. This provides a comprehensive view of each episode, baker performance, and their progression in the competition.

```{r}
star_bakers_table <- final_dataset %>%
  filter(series >= 5 & series <= 10, result %in% c("Star Baker", "WINNER")) |>
  select(series, episode, baker, result) |>
  arrange(series, episode)

star_bakers_table
```

The table shows that there is no predictable overall winner, but the winner of each season is known.

Part two

```{r}
viewers = read_csv("data/viewers.csv") %>%
  janitor::clean_names()

head(viewers, 10)
```

average viewership in Season 1

```{r}
avg_viewers_season1 = mean(viewers$series_1, na.rm = TRUE)

avg_viewers_season1
```

average viewership in Season 5

```{r}
avg_viewers_season5 = mean(viewers$series_5, na.rm = TRUE)

avg_viewers_season5
```

